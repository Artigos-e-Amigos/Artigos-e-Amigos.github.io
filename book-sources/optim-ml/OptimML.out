\BOOKMARK [1][-]{section.1}{Motivation in Machine Learning}{}% 1
\BOOKMARK [2][-]{subsection.1.1}{Unconstraint optimization}{section.1}% 2
\BOOKMARK [2][-]{subsection.1.2}{Regression}{section.1}% 3
\BOOKMARK [2][-]{subsection.1.3}{Classification}{section.1}% 4
\BOOKMARK [1][-]{section.2}{Basics of Convex Analysis}{}% 5
\BOOKMARK [2][-]{subsection.2.1}{Existence of Solutions}{section.2}% 6
\BOOKMARK [2][-]{subsection.2.2}{Convexity}{section.2}% 7
\BOOKMARK [2][-]{subsection.2.3}{Convex Sets}{section.2}% 8
\BOOKMARK [1][-]{section.3}{Derivative and gradient}{}% 9
\BOOKMARK [2][-]{subsection.3.1}{Gradient}{section.3}% 10
\BOOKMARK [2][-]{subsection.3.2}{First Order Conditions}{section.3}% 11
\BOOKMARK [2][-]{subsection.3.3}{Least Squares}{section.3}% 12
\BOOKMARK [2][-]{subsection.3.4}{Link with PCA}{section.3}% 13
\BOOKMARK [2][-]{subsection.3.5}{Classification}{section.3}% 14
\BOOKMARK [2][-]{subsection.3.6}{Chain Rule}{section.3}% 15
\BOOKMARK [1][-]{section.4}{Gradient Descent Algorithm}{}% 16
\BOOKMARK [2][-]{subsection.4.1}{Steepest Descent Direction}{section.4}% 17
\BOOKMARK [2][-]{subsection.4.2}{Gradient Descent}{section.4}% 18
\BOOKMARK [1][-]{section.5}{Convergence Analysis}{}% 19
\BOOKMARK [2][-]{subsection.5.1}{Quadratic Case}{section.5}% 20
\BOOKMARK [2][-]{subsection.5.2}{General Case}{section.5}% 21
\BOOKMARK [2][-]{subsection.5.3}{Acceleration}{section.5}% 22
\BOOKMARK [1][-]{section.6}{Mirror Descent and Implicit Bias}{}% 23
\BOOKMARK [2][-]{subsection.6.1}{Bregman Divergences}{section.6}% 24
\BOOKMARK [2][-]{subsection.6.2}{Mirror descent}{section.6}% 25
\BOOKMARK [2][-]{subsection.6.3}{Re-parameterized flows}{section.6}% 26
\BOOKMARK [2][-]{subsection.6.4}{Implicit Bias}{section.6}% 27
\BOOKMARK [1][-]{section.7}{Regularization}{}% 28
\BOOKMARK [2][-]{subsection.7.1}{Penalized Least Squares}{section.7}% 29
\BOOKMARK [2][-]{subsection.7.2}{Ridge Regression}{section.7}% 30
\BOOKMARK [2][-]{subsection.7.3}{Lasso}{section.7}% 31
\BOOKMARK [2][-]{subsection.7.4}{Iterative Soft Thresholding}{section.7}% 32
\BOOKMARK [1][-]{section.8}{Stochastic Optimization}{}% 33
\BOOKMARK [2][-]{subsection.8.1}{Minimizing Sums and Expectation}{section.8}% 34
\BOOKMARK [2][-]{subsection.8.2}{Batch Gradient Descent \(BGD\)}{section.8}% 35
\BOOKMARK [2][-]{subsection.8.3}{Stochastic Gradient Descent \(SGD\)}{section.8}% 36
\BOOKMARK [2][-]{subsection.8.4}{Stochastic Gradient Descent with Averaging \(SGA\)}{section.8}% 37
\BOOKMARK [2][-]{subsection.8.5}{Stochastic Averaged Gradient Descent \(SAG\)}{section.8}% 38
\BOOKMARK [1][-]{section.9}{Multi-Layers Perceptron}{}% 39
\BOOKMARK [2][-]{subsection.9.1}{MLP and its derivative}{section.9}% 40
\BOOKMARK [2][-]{subsection.9.2}{MLP and Gradient Computation}{section.9}% 41
\BOOKMARK [2][-]{subsection.9.3}{Universality}{section.9}% 42
\BOOKMARK [1][-]{section.10}{Automatic Differentiation}{}% 43
\BOOKMARK [2][-]{subsection.10.1}{Finite Differences and Symbolic Calculus}{section.10}% 44
\BOOKMARK [2][-]{subsection.10.2}{Computational Graphs}{section.10}% 45
\BOOKMARK [2][-]{subsection.10.3}{Forward Mode of Automatic Differentiation}{section.10}% 46
\BOOKMARK [2][-]{subsection.10.4}{Reverse Mode of Automatic Differentiation}{section.10}% 47
\BOOKMARK [2][-]{subsection.10.5}{Feed-forward Compositions}{section.10}% 48
\BOOKMARK [2][-]{subsection.10.6}{Feed-forward Architecture}{section.10}% 49
\BOOKMARK [2][-]{subsection.10.7}{Recurrent Architectures}{section.10}% 50
