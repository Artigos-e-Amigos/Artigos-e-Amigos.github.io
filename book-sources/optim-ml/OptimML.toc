\contentsline {section}{\numberline {1}Motivation in Machine Learning}{2}{section.1}
\contentsline {subsection}{\numberline {1.1}Unconstraint optimization}{2}{subsection.1.1}
\contentsline {subsection}{\numberline {1.2}Regression}{3}{subsection.1.2}
\contentsline {subsection}{\numberline {1.3}Classification}{3}{subsection.1.3}
\contentsline {section}{\numberline {2}Basics of Convex Analysis}{3}{section.2}
\contentsline {subsection}{\numberline {2.1}Existence of Solutions}{3}{subsection.2.1}
\contentsline {subsection}{\numberline {2.2}Convexity}{4}{subsection.2.2}
\contentsline {paragraph}{Strict convexity.}{5}{section*.2}
\contentsline {subsection}{\numberline {2.3}Convex Sets}{5}{subsection.2.3}
\contentsline {section}{\numberline {3}Derivative and gradient}{6}{section.3}
\contentsline {subsection}{\numberline {3.1}Gradient}{6}{subsection.3.1}
\contentsline {subsection}{\numberline {3.2}First Order Conditions}{7}{subsection.3.2}
\contentsline {subsection}{\numberline {3.3}Least Squares}{8}{subsection.3.3}
\contentsline {subsection}{\numberline {3.4}Link with PCA}{8}{subsection.3.4}
\contentsline {subsection}{\numberline {3.5}Classification}{9}{subsection.3.5}
\contentsline {subsection}{\numberline {3.6}Chain Rule}{10}{subsection.3.6}
\contentsline {section}{\numberline {4}Gradient Descent Algorithm}{10}{section.4}
\contentsline {subsection}{\numberline {4.1}Steepest Descent Direction}{10}{subsection.4.1}
\contentsline {subsection}{\numberline {4.2}Gradient Descent}{12}{subsection.4.2}
\contentsline {section}{\numberline {5}Convergence Analysis}{13}{section.5}
\contentsline {subsection}{\numberline {5.1}Quadratic Case}{13}{subsection.5.1}
\contentsline {paragraph}{Convergence analysis for the quadratic case.}{13}{section*.3}
\contentsline {subsection}{\numberline {5.2}General Case}{15}{subsection.5.2}
\contentsline {paragraph}{Hessian.}{15}{section*.4}
\contentsline {paragraph}{Smoothness and strong convexity.}{16}{section*.5}
\contentsline {paragraph}{Convergence analysis.}{17}{section*.6}
\contentsline {subsection}{\numberline {5.3}Acceleration}{19}{subsection.5.3}
\contentsline {section}{\numberline {6}Mirror Descent and Implicit Bias}{19}{section.6}
\contentsline {subsection}{\numberline {6.1}Bregman Divergences}{19}{subsection.6.1}
\contentsline {subsection}{\numberline {6.2}Mirror descent}{21}{subsection.6.2}
\contentsline {paragraph}{Mirror flow.}{21}{section*.7}
\contentsline {paragraph}{Convergence.}{21}{section*.8}
\contentsline {subsection}{\numberline {6.3}Re-parameterized flows}{22}{subsection.6.3}
\contentsline {paragraph}{Dual parameterization}{22}{section*.9}
\contentsline {paragraph}{Example: power-type parameterization}{22}{section*.10}
\contentsline {paragraph}{Counter-example: SDP matrices}{22}{section*.11}
\contentsline {subsection}{\numberline {6.4}Implicit Bias}{23}{subsection.6.4}
\contentsline {section}{\numberline {7}Regularization}{24}{section.7}
\contentsline {subsection}{\numberline {7.1}Penalized Least Squares}{24}{subsection.7.1}
\contentsline {subsection}{\numberline {7.2}Ridge Regression}{24}{subsection.7.2}
\contentsline {paragraph}{Pseudo-inverse.}{25}{section*.12}
\contentsline {subsection}{\numberline {7.3}Lasso}{25}{subsection.7.3}
\contentsline {subsection}{\numberline {7.4}Iterative Soft Thresholding}{26}{subsection.7.4}
\contentsline {section}{\numberline {8}Stochastic Optimization}{27}{section.8}
\contentsline {subsection}{\numberline {8.1}Minimizing Sums and Expectation}{27}{subsection.8.1}
\contentsline {subsection}{\numberline {8.2}Batch Gradient Descent (BGD)}{28}{subsection.8.2}
\contentsline {subsection}{\numberline {8.3}Stochastic Gradient Descent (SGD)}{28}{subsection.8.3}
\contentsline {subsection}{\numberline {8.4}Stochastic Gradient Descent with Averaging (SGA)}{31}{subsection.8.4}
\contentsline {subsection}{\numberline {8.5}Stochastic Averaged Gradient Descent (SAG)}{31}{subsection.8.5}
\contentsline {section}{\numberline {9}Multi-Layers Perceptron}{32}{section.9}
\contentsline {subsection}{\numberline {9.1}MLP and its derivative}{32}{subsection.9.1}
\contentsline {paragraph}{Expressiveness. }{32}{section*.13}
\contentsline {subsection}{\numberline {9.2}MLP and Gradient Computation}{33}{subsection.9.2}
\contentsline {paragraph}{Optimizing with respect to $u$.}{33}{section*.14}
\contentsline {paragraph}{Optimizing with respect to $W$.}{33}{section*.15}
\contentsline {subsection}{\numberline {9.3}Universality}{33}{subsection.9.3}
\contentsline {paragraph}{Proof in dimension $p=1$.}{34}{section*.16}
\contentsline {paragraph}{Proof in arbitrary dimension $p$.}{34}{section*.17}
\contentsline {paragraph}{Quantitative rates.}{35}{section*.18}
\contentsline {section}{\numberline {10}Automatic Differentiation}{36}{section.10}
\contentsline {subsection}{\numberline {10.1}Finite Differences and Symbolic Calculus}{36}{subsection.10.1}
\contentsline {subsection}{\numberline {10.2}Computational Graphs}{36}{subsection.10.2}
\contentsline {subsection}{\numberline {10.3}Forward Mode of Automatic Differentiation}{37}{subsection.10.3}
\contentsline {paragraph}{Simple example.}{37}{section*.19}
\contentsline {paragraph}{Dual numbers.}{38}{section*.20}
\contentsline {subsection}{\numberline {10.4}Reverse Mode of Automatic Differentiation}{39}{subsection.10.4}
\contentsline {paragraph}{Back-propagation.}{39}{section*.21}
\contentsline {paragraph}{Simple example.}{40}{section*.22}
\contentsline {subsection}{\numberline {10.5}Feed-forward Compositions}{40}{subsection.10.5}
\contentsline {subsection}{\numberline {10.6}Feed-forward Architecture}{41}{subsection.10.6}
\contentsline {paragraph}{Multilayers perceptron.}{41}{section*.23}
\contentsline {paragraph}{Link with adjoint state method.}{42}{section*.24}
\contentsline {subsection}{\numberline {10.7}Recurrent Architectures}{42}{subsection.10.7}
\contentsline {paragraph}{Residual recurrent networks. }{43}{section*.25}
\contentsline {paragraph}{Mitigating memory requirement. }{43}{section*.26}
\contentsline {paragraph}{Fixed point maps}{44}{section*.27}
\contentsline {paragraph}{Argmin layers}{44}{section*.28}
\contentsline {paragraph}{Sinkhorn's algorithm}{44}{section*.29}
