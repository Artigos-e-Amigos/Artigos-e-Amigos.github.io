\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\zref@newlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {14}Optimization \& Machine Learning: Advanced Topics}{235}{chapter.14}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{c-smooth-optim-advanced}{{14}{235}{Optimization \& Machine Learning: Advanced Topics}{chapter.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {14.1}Regularization}{235}{section.14.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.1.1}Penalized Least Squares}{235}{subsection.14.1.1}}
\newlabel{eq-regul-ls}{{14.1}{235}{Penalized Least Squares}{equation.14.1.1}{}}
\newlabel{eq-regul-constr}{{14.2}{235}{}{equation.14.1.2}{}}
\newlabel{eq-ineq-proof-regul}{{14.3}{235}{Penalized Least Squares}{equation.14.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.1.2}Ridge Regression}{235}{subsection.14.1.2}}
\newlabel{eq-regul-ls-1}{{14.4}{236}{}{equation.14.1.4}{}}
\newlabel{eq-regul-ls-2}{{14.5}{236}{}{equation.14.1.5}{}}
\@writefile{toc}{\contentsline {paragraph}{Pseudo-inverse.}{236}{section*.135}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.1}{\ignorespaces $\ell ^q$ balls $ \left \{ x \tmspace  +\thickmuskip {.2777em};\tmspace  +\thickmuskip {.2777em} \DOTSB \sum@ \slimits@ _k |x_k|^q \leqslant 1 \right \} $ for varying $q$. }}{236}{figure.14.1}}
\newlabel{fig-sparsity-lq}{{14.1}{236}{$\ell ^q$ balls $\enscond {x}{\sum _k |x_k|^q \leq 1}$ for varying $q$}{figure.14.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.1.3}Lasso}{237}{subsection.14.1.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.2}{\ignorespaces Evolution with $\lambda $ of the function $F(x) \ensuremath  {\mathrel {\mathop {=}\limits ^{\unhbox \voidb@x \hbox {\upshape  \relax \fontsize  {5}{6}\selectfont  def.}}}}\frac  {1}{2}|\tmspace  -\thinmuskip {.1667em}| \cdot -y |\tmspace  -\thinmuskip {.1667em}|^2+\lambda |\cdot |$. }}{237}{figure.14.2}}
\newlabel{fig-varspars}{{14.2}{237}{Evolution with $\la $ of the function $F(x) \eqdef \frac {1}{2}\norm {\cdot -y}^2+\la |\cdot |$}{figure.14.2}{}}
\newlabel{prop-soft-tresdh}{{50}{237}{}{prop.50}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.1.4}Iterative Soft Thresholding}{237}{subsection.14.1.4}}
\newlabel{sec-ista}{{14.1.4}{237}{Iterative Soft Thresholding}{subsection.14.1.4}{}}
\newlabel{eq-ista-surrog}{{14.6}{238}{Iterative Soft Thresholding}{equation.14.1.6}{}}
\newlabel{eq-ista}{{14.7}{238}{}{equation.14.1.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {14.2}Stochastic Optimization}{238}{section.14.2}}
\newlabel{sec-stochastic-optim}{{14.2}{238}{Stochastic Optimization}{section.14.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.2.1}Minimizing Sums and Expectation}{239}{subsection.14.2.1}}
\newlabel{eq-min-sums}{{14.8}{239}{Minimizing Sums and Expectation}{equation.14.2.8}{}}
\newlabel{eq-min-int}{{14.9}{239}{Minimizing Sums and Expectation}{equation.14.2.9}{}}
\newlabel{eq-stochastic-erm}{{14.10}{239}{Minimizing Sums and Expectation}{equation.14.2.10}{}}
\newlabel{eq-stoch-logistic}{{14.11}{239}{Minimizing Sums and Expectation}{equation.14.2.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.2.2}Batch Gradient Descent (BGD)}{239}{subsection.14.2.2}}
\newlabel{eq-full-grad}{{14.12}{239}{Batch Gradient Descent (BGD)}{equation.14.2.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.3}{\ignorespaces  Evolution of the error of the BGD for logistic classification. }}{240}{figure.14.3}}
\newlabel{fig-bgd}{{14.3}{240}{Evolution of the error of the BGD for logistic classification}{figure.14.3}{}}
\newlabel{eq-grad-formula}{{14.13}{240}{Batch Gradient Descent (BGD)}{equation.14.2.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.2.3}Stochastic Gradient Descent (SGD)}{240}{subsection.14.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.4}{\ignorespaces Unbiased gradient estimate}}{240}{figure.14.4}}
\newlabel{eq-unbiased-grad}{{14.14}{240}{Stochastic Gradient Descent (SGD)}{equation.14.2.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.5}{\ignorespaces Schematic view of SGD iterates}}{240}{figure.14.5}}
\newlabel{eq-stepsize-sgd}{{14.15}{240}{Stochastic Gradient Descent (SGD)}{equation.14.2.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.6}{\ignorespaces  Display of a large number of trajectories $k \DOTSB \mapstochar \rightarrow x_k \in \mathbb  {R}$ generated by several runs of SGD. On the top row, each curve is a trajectory, and the bottom row displays the corresponding density. }}{241}{figure.14.6}}
\newlabel{fig-sgd-traject}{{14.6}{241}{Display of a large number of trajectories $k \mapsto x_k \in \RR $ generated by several runs of SGD. On the top row, each curve is a trajectory, and the bottom row displays the corresponding density}{figure.14.6}{}}
\newlabel{thm-conv-sgd}{{25}{241}{}{thm.25}{}}
\newlabel{eq-rate-sgd}{{14.16}{241}{}{equation.14.2.16}{}}
\newlabel{eq-sgd-proof-1}{{14.17}{241}{Stochastic Gradient Descent (SGD)}{equation.14.2.17}{}}
\newlabel{eq-sgd-proof-2}{{14.18}{241}{Stochastic Gradient Descent (SGD)}{equation.14.2.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.7}{\ignorespaces  Evolution of the error of the SGD for logistic classification (dashed line shows BGD). }}{242}{figure.14.7}}
\newlabel{fig-sgd}{{14.7}{242}{Evolution of the error of the SGD for logistic classification (dashed line shows BGD)}{figure.14.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.2.4}Stochastic Gradient Descent with Averaging (SGA)}{242}{subsection.14.2.4}}
\newlabel{sec-sga}{{14.2.4}{242}{Stochastic Gradient Descent with Averaging (SGA)}{subsection.14.2.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.8}{\ignorespaces  Evolution of $\qopname  \relax o{log}_{10}(f(x_k)-f(x^\star ))$ for SGD, SGA and SAG. }}{243}{figure.14.8}}
\newlabel{fig-compariso-sgd}{{14.8}{243}{Evolution of $\log _{10}(f(x_k)-f(x^\star ))$ for SGD, SGA and SAG}{figure.14.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.2.5}Stochastic Averaged Gradient Descent (SAG)}{243}{subsection.14.2.5}}
\@writefile{toc}{\contentsline {section}{\numberline {14.3}Automatic Differentiation}{243}{section.14.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.9}{\ignorespaces  A computational graph. }}{244}{figure.14.9}}
\newlabel{fig-compgraph}{{14.9}{244}{A computational graph}{figure.14.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.3.1}Finite Differences and Symbolic Calculus}{244}{subsection.14.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.3.2}Computational Graphs}{244}{subsection.14.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.3.3}Forward Mode of Automatic Differentiation}{244}{subsection.14.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.10}{\ignorespaces  Relation between the variable for the forward (left) and backward (right) modes. }}{245}{figure.14.10}}
\newlabel{fig-forward-backward}{{14.10}{245}{Relation between the variable for the forward (left) and backward (right) modes}{figure.14.10}{}}
\@writefile{toc}{\contentsline {paragraph}{Simple example.}{245}{section*.136}}
\newlabel{eq-simple-func-autodiff}{{14.19}{245}{Simple example}{equation.14.3.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.11}{\ignorespaces  Example of a simple computational graph. }}{246}{figure.14.11}}
\newlabel{fig-dag-example-simple}{{14.11}{246}{Example of a simple computational graph}{figure.14.11}{}}
\@writefile{toc}{\contentsline {paragraph}{Dual numbers.}{246}{section*.137}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.3.4}Reverse Mode of Automatic Differentiation}{247}{subsection.14.3.4}}
\@writefile{toc}{\contentsline {paragraph}{Back-propagation.}{247}{section*.138}}
\@writefile{toc}{\contentsline {paragraph}{Simple example.}{247}{section*.139}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.12}{\ignorespaces  Complexity of forward (left) and backward (right) modes for composition of functions. }}{248}{figure.14.12}}
\newlabel{fig-matrix-mult}{{14.12}{248}{Complexity of forward (left) and backward (right) modes for composition of functions}{figure.14.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.3.5}Feed-forward Compositions}{248}{subsection.14.3.5}}
\newlabel{eq-simple-lin-dag}{{14.20}{248}{Feed-forward Compositions}{equation.14.3.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.3.6}Feed-forward Architecture}{248}{subsection.14.3.6}}
\newlabel{eq-feednets}{{14.21}{248}{Feed-forward Architecture}{equation.14.3.21}{}}
\newlabel{eq-loss-feedf}{{14.22}{248}{Feed-forward Architecture}{equation.14.3.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.13}{\ignorespaces  Computational graph for a feedforward architecture. }}{249}{figure.14.13}}
\newlabel{fig-mlp}{{14.13}{249}{Computational graph for a feedforward architecture}{figure.14.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.14}{\ignorespaces  Multi-layer perceptron parameterization. }}{249}{figure.14.14}}
\newlabel{fig-mlp-param}{{14.14}{249}{Multi-layer perceptron parameterization}{figure.14.14}{}}
\newlabel{eq-backprop-discr}{{14.23}{249}{Feed-forward Architecture}{equation.14.3.23}{}}
\@writefile{toc}{\contentsline {paragraph}{Multilayers perceptron.}{249}{section*.140}}
\newlabel{eq-mlp-func}{{14.24}{249}{Multilayers perceptron}{equation.14.3.24}{}}
\@writefile{toc}{\contentsline {paragraph}{Link with adjoint state method.}{249}{section*.141}}
\newlabel{eq-flow-eq}{{14.25}{249}{Link with adjoint state method}{equation.14.3.25}{}}
\newlabel{eq-ode-structure}{{14.26}{249}{Link with adjoint state method}{equation.14.3.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.15}{\ignorespaces  Computational graph for a recurrent architecture. }}{250}{figure.14.15}}
\newlabel{fig-recur}{{14.15}{250}{Computational graph for a recurrent architecture}{figure.14.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.3.7}Recurrent Architectures}{250}{subsection.14.3.7}}
\newlabel{eq-feednets-recur}{{14.27}{250}{Recurrent Architectures}{equation.14.3.27}{}}
\newlabel{eq-backprop-discr}{{14.28}{250}{Recurrent Architectures}{equation.14.3.28}{}}
\newlabel{eq-jacobian-mlp}{{14.29}{250}{Recurrent Architectures}{equation.14.3.29}{}}
\@writefile{toc}{\contentsline {paragraph}{Residual recurrent networks. }{250}{section*.142}}
\@writefile{toc}{\contentsline {paragraph}{Mitigating memory requirement. }{250}{section*.143}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.16}{\ignorespaces  Recurrent residual perceptron parameterization. }}{251}{figure.14.16}}
\newlabel{fig-recurrent-param}{{14.16}{251}{Recurrent residual perceptron parameterization}{figure.14.16}{}}
\@writefile{toc}{\contentsline {paragraph}{Fixed point maps}{251}{section*.144}}
\newlabel{eq-impl-func-formula}{{14.30}{251}{Fixed point maps}{equation.14.3.30}{}}
\@writefile{toc}{\contentsline {paragraph}{Argmin layers}{251}{section*.145}}
\newlabel{eq-argmin-layer}{{14.31}{251}{Argmin layers}{equation.14.3.31}{}}
\newlabel{eq-danskin}{{14.32}{252}{Argmin layers}{equation.14.3.32}{}}
\@writefile{toc}{\contentsline {paragraph}{Sinkhorn's algorithm}{252}{section*.146}}
\@setckpt{chapters/optim-ml-advanced}{
\setcounter{page}{253}
\setcounter{equation}{32}
\setcounter{enumi}{3}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{14}
\setcounter{section}{3}
\setcounter{subsection}{7}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{16}
\setcounter{table}{0}
\setcounter{Item}{3}
\setcounter{Hfootnote}{3}
\setcounter{bookmark@seq@number}{238}
\setcounter{parentequation}{0}
\setcounter{subfigure}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{lotdepth}{1}
\setcounter{thm}{25}
\setcounter{prop}{51}
\setcounter{defn}{1}
\setcounter{cor}{0}
\setcounter{alg}{0}
\setcounter{lem}{9}
\setcounter{rem}{10}
\setcounter{exmp}{8}
\setcounter{float@type}{32}
\setcounter{listing}{0}
\setcounter{lstnumber}{1}
\setcounter{mdf@globalstyle@cnt}{0}
\setcounter{mdfcountframes}{0}
\setcounter{mdf@env@i}{0}
\setcounter{mdf@env@ii}{0}
\setcounter{mdf@zref@counter}{0}
\setcounter{AM@survey}{0}
\setcounter{section@level}{4}
\setcounter{lstlisting}{0}
}
