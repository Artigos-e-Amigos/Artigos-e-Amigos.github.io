\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\zref@newlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {13}Optimization \& Machine Learning: Smooth Optimization}{217}{chapter.13}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{c-smooth-optim}{{13}{217}{Optimization \& Machine Learning: Smooth Optimization}{chapter.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.1}Motivation in Machine Learning}{217}{section.13.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.1.1}Unconstraint optimization}{217}{subsection.13.1.1}}
\newlabel{eq-general-pbm}{{13.1}{217}{Unconstraint optimization}{equation.13.1.1}{}}
\newlabel{eq-general-pbm-min}{{13.2}{217}{Unconstraint optimization}{equation.13.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.1}{\ignorespaces  Left: linear regression, middle: linear classifier, right: loss function for classification. }}{217}{figure.13.1}}
\newlabel{fig-ml-ex}{{13.1}{217}{Left: linear regression, middle: linear classifier, right: loss function for classification}{figure.13.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.2}{\ignorespaces  Left: non-existence of minimizer, middle: multiple minimizers, right: uniqueness. }}{218}{figure.13.2}}
\newlabel{fig-minimizer-exists}{{13.2}{218}{Left: non-existence of minimizer, middle: multiple minimizers, right: uniqueness}{figure.13.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.1.2}Regression}{218}{subsection.13.1.2}}
\newlabel{eq-least-square}{{13.3}{218}{Regression}{equation.13.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.1.3}Classification}{218}{subsection.13.1.3}}
\newlabel{eq-classif}{{13.4}{218}{Classification}{equation.13.1.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.2}Basics of Convex Analysis}{218}{section.13.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.2.1}Existence of Solutions}{218}{subsection.13.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.3}{\ignorespaces  Coercivity condition for least squares. }}{219}{figure.13.3}}
\newlabel{fig-least-square}{{13.3}{219}{Coercivity condition for least squares}{figure.13.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.4}{\ignorespaces  Convex vs. non-convex functions ; Strictly convex vs. non strictly convex functions. }}{219}{figure.13.4}}
\newlabel{fig-cvx-vs-noncvx}{{13.4}{219}{Convex vs. non-convex functions ; Strictly convex vs. non strictly convex functions}{figure.13.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.2.2}Convexity}{219}{subsection.13.2.2}}
\newlabel{eq-convexity-def}{{13.5}{219}{Convexity}{equation.13.2.5}{}}
\@writefile{toc}{\contentsline {paragraph}{Strict convexity.}{219}{section*.130}}
\newlabel{eq-strict-convexity-def}{{13.6}{219}{Strict convexity}{equation.13.2.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.5}{\ignorespaces  Comparison of convex functions $f : \mathbb  {R}^p \rightarrow \mathbb  {R}$ (for $p=1$) and convex sets $C \subset \mathbb  {R}^p$ (for $p=2$). }}{220}{figure.13.5}}
\newlabel{fig-cvx-set}{{13.5}{220}{Comparison of convex functions $f : \RR ^p \rightarrow \RR $ (for $p=1$) and convex sets $C \subset \RR ^p$ (for $p=2$)}{figure.13.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.2.3}Convex Sets}{220}{subsection.13.2.3}}
\@writefile{toc}{\contentsline {section}{\numberline {13.3}Derivative and gradient}{220}{section.13.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3.1}Gradient}{220}{subsection.13.3.1}}
\newlabel{eq-grad-dfn}{{13.7}{220}{Gradient}{equation.13.3.7}{}}
\newlabel{prop-above-tgt}{{42}{221}{}{prop.42}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3.2}First Order Conditions}{221}{subsection.13.3.2}}
\newlabel{prop-cs-min}{{43}{221}{}{prop.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.6}{\ignorespaces  Function with local maxima/minima (left), saddle point (middle) and global minimum (right). }}{222}{figure.13.6}}
\newlabel{fig-first-order}{{13.6}{222}{Function with local maxima/minima (left), saddle point (middle) and global minimum (right)}{figure.13.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3.3}Least Squares}{222}{subsection.13.3.3}}
\newlabel{eq-grad-ls}{{13.8}{222}{Least Squares}{equation.13.3.8}{}}
\newlabel{eq-sol-leastsquare}{{13.9}{222}{Least Squares}{equation.13.3.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.7}{\ignorespaces  Left: point clouds $(a_i)_i$ with associated PCA directions, right: quadratic part of $f(x)$. }}{223}{figure.13.7}}
\newlabel{fig-link-pca}{{13.7}{223}{Left: point clouds $(a_i)_i$ with associated PCA directions, right: quadratic part of $f(x)$}{figure.13.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3.4}Link with PCA}{223}{subsection.13.3.4}}
\newlabel{eq-pca-decomp}{{13.10}{223}{Link with PCA}{equation.13.3.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3.5}Classification}{224}{subsection.13.3.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3.6}Chain Rule}{224}{subsection.13.3.6}}
\newlabel{eq-grad-composition-linear}{{13.11}{224}{Chain Rule}{equation.13.3.11}{}}
\newlabel{eq-differential-defn}{{13.12}{224}{Chain Rule}{equation.13.3.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.8}{\ignorespaces  Left: First order Taylor expansion in 1-D and 2-D. Right: orthogonality of gradient and level sets and schematic of the proof. }}{225}{figure.13.8}}
\newlabel{fig-expansion-taylor}{{13.8}{225}{Left: First order Taylor expansion in 1-D and 2-D. Right: orthogonality of gradient and level sets and schematic of the proof}{figure.13.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.4}Gradient Descent Algorithm}{225}{section.13.4}}
\newlabel{sec-grad-desc-basic}{{13.4}{225}{Gradient Descent Algorithm}{section.13.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.4.1}Steepest Descent Direction}{225}{subsection.13.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.9}{\ignorespaces  Influence of $\tau $ on the gradient descent (left) and optimal step size choice (right). }}{226}{figure.13.9}}
\newlabel{fig-gradesc}{{13.9}{226}{Influence of $\tau $ on the gradient descent (left) and optimal step size choice (right)}{figure.13.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.4.2}Gradient Descent}{226}{subsection.13.4.2}}
\newlabel{eq-grad-desc}{{13.13}{226}{Gradient Descent}{equation.13.4.13}{}}
\newlabel{eq-armijo-rule}{{13.14}{227}{Armijo rule}{equation.13.4.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.5}Convergence Analysis}{227}{section.13.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.5.1}Quadratic Case}{227}{subsection.13.5.1}}
\@writefile{toc}{\contentsline {paragraph}{Convergence analysis for the quadratic case.}{227}{section*.131}}
\newlabel{prop-graddesc-quad}{{45}{227}{}{prop.45}{}}
\newlabel{eq-global-linrate-grad}{{13.15}{227}{}{equation.13.5.15}{}}
\newlabel{eq-best-rate-local}{{13.16}{227}{}{equation.13.5.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.10}{\ignorespaces  Contraction constant $h(\tau )$ for a quadratic function (right). }}{228}{figure.13.10}}
\newlabel{fig-grad-desc-contract}{{13.10}{228}{Contraction constant $h(\tau )$ for a quadratic function (right)}{figure.13.10}{}}
\newlabel{eq-rate-strong-quad}{{13.17}{228}{Convergence analysis for the quadratic case}{equation.13.5.17}{}}
\newlabel{prop-graddesc-quad-sublin}{{46}{229}{}{prop.46}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.5.2}General Case}{230}{subsection.13.5.2}}
\@writefile{toc}{\contentsline {paragraph}{Hessian.}{230}{section*.132}}
\newlabel{eq-taylor-hess}{{13.18}{230}{Hessian}{equation.13.5.18}{}}
\@writefile{toc}{\contentsline {paragraph}{Smoothness and strong convexity.}{231}{section*.133}}
\newlabel{eq-lipsch-grad}{{{$\mathcal  {R}_L$}}{231}{Smoothness and strong convexity}{equation.13.5.19}{}}
\newlabel{eq-strong-conv}{{{$\mathcal  {S}_\mu $}}{231}{Smoothness and strong convexity}{equation.13.5.19}{}}
\newlabel{prop-smooth-strong}{{47}{231}{}{prop.47}{}}
\newlabel{eq-above-below-quad}{{13.19}{231}{}{equation.13.5.19}{}}
\newlabel{eq-upper-lower-bound-hess}{{13.20}{231}{}{equation.13.5.20}{}}
\@writefile{toc}{\contentsline {paragraph}{Convergence analysis.}{232}{section*.134}}
\newlabel{thm-gradsec-non-strong-conv}{{24}{232}{}{thm.24}{}}
\newlabel{eq-sublin-rate-gd}{{13.21}{232}{}{equation.13.5.21}{}}
\newlabel{eq-proox-x'rad-nonstrong-1}{{13.22}{232}{Convergence analysis}{equation.13.5.22}{}}
\newlabel{eq-conv-rate-proof-1}{{13.25}{232}{Convergence analysis}{equation.13.5.25}{}}
\newlabel{eq-rate-strong}{{13.26}{233}{Convergence analysis}{equation.13.5.26}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.5.3}Acceleration}{233}{subsection.13.5.3}}
\@setckpt{chapters/optim-ml-smooth}{
\setcounter{page}{235}
\setcounter{equation}{26}
\setcounter{enumi}{3}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{13}
\setcounter{section}{5}
\setcounter{subsection}{3}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{10}
\setcounter{table}{0}
\setcounter{Item}{3}
\setcounter{Hfootnote}{3}
\setcounter{bookmark@seq@number}{218}
\setcounter{parentequation}{0}
\setcounter{subfigure}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{lotdepth}{1}
\setcounter{thm}{24}
\setcounter{prop}{47}
\setcounter{defn}{1}
\setcounter{cor}{0}
\setcounter{alg}{0}
\setcounter{lem}{9}
\setcounter{rem}{10}
\setcounter{exmp}{8}
\setcounter{float@type}{32}
\setcounter{listing}{0}
\setcounter{lstnumber}{1}
\setcounter{mdf@globalstyle@cnt}{0}
\setcounter{mdfcountframes}{0}
\setcounter{mdf@env@i}{0}
\setcounter{mdf@env@ii}{0}
\setcounter{mdf@zref@counter}{0}
\setcounter{AM@survey}{0}
\setcounter{section@level}{2}
\setcounter{lstlisting}{0}
}
