\contentsline {chapter}{\numberline {1}Shannon Theory}{13}{chapter.1}
\contentsline {section}{\numberline {1.1}Analog vs. Discrete Signals}{13}{section.1.1}
\contentsline {subsection}{\numberline {1.1.1}Acquisition and Sampling}{13}{subsection.1.1.1}
\contentsline {subsection}{\numberline {1.1.2}Linear Translation Invariant Sampler}{14}{subsection.1.1.2}
\contentsline {section}{\numberline {1.2}Shannon Sampling Theorem}{15}{section.1.2}
\contentsline {paragraph}{Reminders about Fourier transform.}{15}{section*.3}
\contentsline {paragraph}{Reminders about Fourier series.}{15}{section*.4}
\contentsline {paragraph}{Poisson formula.}{16}{section*.5}
\contentsline {paragraph}{Shannon theorem.}{16}{section*.6}
\contentsline {paragraph}{Quantization.}{18}{section*.7}
\contentsline {section}{\numberline {1.3}Shannon Source Coding Theorem}{19}{section.1.3}
\contentsline {paragraph}{Uniform coding.}{19}{section*.8}
\contentsline {paragraph}{Prefix coding.}{19}{section*.9}
\contentsline {paragraph}{Probabilistic modeling.}{20}{section*.10}
\contentsline {paragraph}{Shannon theorem.}{21}{section*.11}
\contentsline {paragraph}{Doing better.}{23}{section*.12}
\contentsline {chapter}{\numberline {2}Fourier Transforms}{25}{chapter.2}
\contentsline {section}{\numberline {2.1}Hilbert spaces and Fourier Transforms}{25}{section.2.1}
\contentsline {subsection}{\numberline {2.1.1}Hilbertian bases.}{25}{subsection.2.1.1}
\contentsline {subsection}{\numberline {2.1.2}Fourier basis on $\mathbb {R}/2\pi \mathbb {Z}$.}{26}{subsection.2.1.2}
\contentsline {section}{\numberline {2.2}Convolution on $\mathbb {R}$ and $\mathbb {T}$}{27}{section.2.2}
\contentsline {subsection}{\numberline {2.2.1}Convolution}{27}{subsection.2.2.1}
\contentsline {subsection}{\numberline {2.2.2}Translation Invariant Operators}{28}{subsection.2.2.2}
\contentsline {subsection}{\numberline {2.2.3}Revisiting Poisson formula using distributions.}{30}{subsection.2.2.3}
\contentsline {section}{\numberline {2.3}Finite Fourier Transform and Convolution}{31}{section.2.3}
\contentsline {subsection}{\numberline {2.3.1}Discrete Ortho-bases}{31}{subsection.2.3.1}
\contentsline {subsection}{\numberline {2.3.2}Discrete Fourier transform}{32}{subsection.2.3.2}
\contentsline {subsection}{\numberline {2.3.3}Fast Fourier transform}{32}{subsection.2.3.3}
\contentsline {subsection}{\numberline {2.3.4}Finite convolution}{33}{subsection.2.3.4}
\contentsline {section}{\numberline {2.4}Discretisation Issues}{34}{section.2.4}
\contentsline {subsection}{\numberline {2.4.1}Fourier approximation via spatial zero padding.}{34}{subsection.2.4.1}
\contentsline {subsection}{\numberline {2.4.2}Fourier interpolation via spectral zero padding.}{34}{subsection.2.4.2}
\contentsline {section}{\numberline {2.5}Fourier in Multiple Dimensions}{35}{section.2.5}
\contentsline {subsection}{\numberline {2.5.1}On Continuous Domains}{35}{subsection.2.5.1}
\contentsline {paragraph}{On $\mathbb {R}^d$.}{35}{figure.2.13}
\contentsline {paragraph}{On $(\mathbb {R}/2\pi \mathbb {Z})^d$.}{36}{section*.14}
\contentsline {subsection}{\numberline {2.5.2}On Discrete Domains}{37}{subsection.2.5.2}
\contentsline {paragraph}{Discrete Fourier Transform.}{37}{figure.2.16}
\contentsline {paragraph}{Fast Fourier Transform.}{37}{section*.16}
\contentsline {subsection}{\numberline {2.5.3}Shannon sampling theorem.}{38}{subsection.2.5.3}
\contentsline {subsection}{\numberline {2.5.4}Convolution in higher dimension.}{38}{subsection.2.5.4}
\contentsline {section}{\numberline {2.6}Application to ODEs and PDEs}{38}{section.2.6}
\contentsline {subsection}{\numberline {2.6.1}On Continuous Domains}{38}{subsection.2.6.1}
\contentsline {subsection}{\numberline {2.6.2}Finite Domain and Discretization}{39}{subsection.2.6.2}
\contentsline {section}{\numberline {2.7}A Bit of Group Theory}{39}{section.2.7}
\contentsline {subsection}{\numberline {2.7.1}Characters}{39}{subsection.2.7.1}
\contentsline {paragraph}{Commutative groups.}{40}{section*.17}
\contentsline {paragraph}{Discrete Fourier transform from character's point of view.}{41}{section*.18}
\contentsline {subsection}{\numberline {2.7.2}More General cases}{41}{subsection.2.7.2}
\contentsline {paragraph}{Infinite groups.}{41}{section*.19}
\contentsline {paragraph}{Non-commutative groups.}{41}{section*.20}
\contentsline {section}{\numberline {2.8}A Bit of Spectral Theory}{43}{section.2.8}
\contentsline {subsection}{\numberline {2.8.1}On a Surface or a Manifold}{43}{subsection.2.8.1}
\contentsline {subsection}{\numberline {2.8.2}Spherical Harmonics}{43}{subsection.2.8.2}
\contentsline {subsection}{\numberline {2.8.3}On a Graph}{43}{subsection.2.8.3}
\contentsline {subsection}{\numberline {2.8.4}Other things}{44}{subsection.2.8.4}
\contentsline {chapter}{\numberline {3}Wavelets}{45}{chapter.3}
\contentsline {section}{\numberline {3.1}Multi-resolution Approximation Spaces}{45}{section.3.1}
\contentsline {paragraph}{Scaling functions.}{45}{section*.21}
\contentsline {paragraph}{Spectral orthogonalization.}{46}{section*.22}
\contentsline {section}{\numberline {3.2}Multi-resolution Details Spaces}{47}{section.3.2}
\contentsline {paragraph}{Haar wavelets.}{48}{section*.23}
\contentsline {paragraph}{Shannon and splines.}{48}{section*.24}
\contentsline {section}{\numberline {3.3}On Bounded Domains}{49}{section.3.3}
\contentsline {section}{\numberline {3.4}Fast Wavelet Transform}{49}{section.3.4}
\contentsline {subsection}{\numberline {3.4.1}Discretization}{49}{subsection.3.4.1}
\contentsline {subsection}{\numberline {3.4.2}Forward Fast Wavelet Transform (FWT)}{50}{subsection.3.4.2}
\contentsline {paragraph}{Fast Haar transform.}{52}{section*.25}
\contentsline {subsection}{\numberline {3.4.3}Inverse Fast Transform (iFWT)}{53}{subsection.3.4.3}
\contentsline {section}{\numberline {3.5}2-D Wavelets}{55}{section.3.5}
\contentsline {subsection}{\numberline {3.5.1}Anisotropic Wavelets}{55}{subsection.3.5.1}
\contentsline {subsection}{\numberline {3.5.2}Isotropic Wavelets}{55}{subsection.3.5.2}
\contentsline {paragraph}{Haar 2-D multiresolution.}{57}{section*.26}
\contentsline {paragraph}{Discrete 2-D wavelet coefficients.}{57}{section*.27}
\contentsline {paragraph}{Forward 2-D wavelet transform basic step.}{57}{section*.28}
\contentsline {paragraph}{Fast 2-D wavelet transform.}{58}{section*.29}
\contentsline {paragraph}{Fast 2-D inverse wavelet transform.}{59}{section*.30}
\contentsline {section}{\numberline {3.6}Wavelet Design}{60}{section.3.6}
\contentsline {subsection}{\numberline {3.6.1}Low-pass Filter Constraints}{60}{subsection.3.6.1}
\contentsline {subsection}{\numberline {3.6.2}High-pass Filter Constraints}{62}{subsection.3.6.2}
\contentsline {paragraph}{Quadrature mirror filters.}{63}{section*.31}
\contentsline {subsection}{\numberline {3.6.3}Wavelet Design Constraints}{64}{subsection.3.6.3}
\contentsline {paragraph}{Vanishing moments.}{64}{section*.32}
\contentsline {paragraph}{Support.}{65}{section*.33}
\contentsline {paragraph}{Smoothness.}{65}{section*.34}
\contentsline {subsection}{\numberline {3.6.4}Daubechies Wavelets}{66}{subsection.3.6.4}
\contentsline {paragraph}{Wavelet display.}{67}{section*.35}
\contentsline {chapter}{\numberline {4}Linear and Non-linear Approximation}{69}{chapter.4}
\contentsline {section}{\numberline {4.1}Approximation}{69}{section.4.1}
\contentsline {subsection}{\numberline {4.1.1}Approximation in an Ortho-basis}{69}{subsection.4.1.1}
\contentsline {subsection}{\numberline {4.1.2}Linear Approximation}{69}{subsection.4.1.2}
\contentsline {subsection}{\numberline {4.1.3}Non-linear Approximation}{70}{subsection.4.1.3}
\contentsline {paragraph}{Computation of the threshold.}{70}{section*.36}
\contentsline {paragraph}{Hard thresholding.}{71}{section*.37}
\contentsline {section}{\numberline {4.2}Signal and Image Modeling}{71}{section.4.2}
\contentsline {subsection}{\numberline {4.2.1}Uniformly Smooth Signals and Images}{71}{subsection.4.2.1}
\contentsline {paragraph}{Signals with derivatives.}{71}{section*.38}
\contentsline {paragraph}{Sobolev smooth signals and images.}{72}{section*.39}
\contentsline {subsection}{\numberline {4.2.2}Piecewise Regular Signals and Images}{73}{subsection.4.2.2}
\contentsline {paragraph}{Piecewise smooth signals.}{73}{section*.40}
\contentsline {paragraph}{Piecewise smooth images.}{73}{section*.41}
\contentsline {subsection}{\numberline {4.2.3}Bounded Variation Signals and Images}{73}{subsection.4.2.3}
\contentsline {subsection}{\numberline {4.2.4}Cartoon Images}{74}{subsection.4.2.4}
\contentsline {section}{\numberline {4.3}Efficient approximation}{74}{section.4.3}
\contentsline {subsection}{\numberline {4.3.1}Decay of Approximation Error}{74}{subsection.4.3.1}
\contentsline {paragraph}{Polynomial error decay.}{75}{section*.42}
\contentsline {paragraph}{Relevance for compression, denoising and inverse problems.}{75}{section*.43}
\contentsline {paragraph}{Comparison of signals.}{75}{section*.44}
\contentsline {subsection}{\numberline {4.3.2}Comparison of bases.}{75}{subsection.4.3.2}
\contentsline {section}{\numberline {4.4}Fourier Linear Approximation of Smooth Functions}{76}{section.4.4}
\contentsline {subsection}{\numberline {4.4.1}1-D Fourier Approximation}{76}{subsection.4.4.1}
\contentsline {paragraph}{Low pass approximation.}{77}{section*.45}
\contentsline {subsection}{\numberline {4.4.2}Sobolev Images}{79}{subsection.4.4.2}
\contentsline {section}{\numberline {4.5}Wavelet Approximation of Piecewise Smooth Functions}{79}{section.4.5}
\contentsline {subsection}{\numberline {4.5.1}Decay of Wavelet Coefficients}{79}{subsection.4.5.1}
\contentsline {subsection}{\numberline {4.5.2}1-D Piecewise Smooth Approximation}{80}{subsection.4.5.2}
\contentsline {paragraph}{Step 1. Coefficient segmentation.}{81}{section*.46}
\contentsline {paragraph}{Step 2. Counting the error.}{81}{section*.47}
\contentsline {paragraph}{Step 3. Counting the number of measurements.}{82}{section*.48}
\contentsline {paragraph}{Step 3. Putting everything together.}{82}{section*.49}
\contentsline {subsection}{\numberline {4.5.3}2-D Piecewise Smooth Approximation}{82}{subsection.4.5.3}
\contentsline {section}{\numberline {4.6}Cartoon Images Approximation}{83}{section.4.6}
\contentsline {subsection}{\numberline {4.6.1}Wavelet Approximation of Cartoon Images}{83}{subsection.4.6.1}
\contentsline {subsection}{\numberline {4.6.2}Finite Element Approximation}{84}{subsection.4.6.2}
\contentsline {subsection}{\numberline {4.6.3}Curvelets Approximation}{85}{subsection.4.6.3}
\contentsline {paragraph}{Curvelets.}{85}{section*.50}
\contentsline {paragraph}{Parameter discretization.}{86}{section*.51}
\contentsline {paragraph}{Curvelet tight frame.}{87}{section*.52}
\contentsline {paragraph}{Curvelet approximation.}{87}{section*.53}
\contentsline {chapter}{\numberline {5}Compression}{89}{chapter.5}
\contentsline {section}{\numberline {5.1}Transform Coding}{89}{section.5.1}
\contentsline {subsection}{\numberline {5.1.1}Coding}{89}{subsection.5.1.1}
\contentsline {subsection}{\numberline {5.1.2}De-coding}{90}{subsection.5.1.2}
\contentsline {subsection}{\numberline {5.1.3}Support Coding}{90}{subsection.5.1.3}
\contentsline {paragraph}{Signals constraints.}{91}{section*.54}
\contentsline {paragraph}{Discrete computation and scaling of $N$.}{91}{section*.55}
\contentsline {paragraph}{Support coding.}{91}{section*.56}
\contentsline {paragraph}{Values coding.}{91}{section*.57}
\contentsline {paragraph}{Total number of bits.}{92}{section*.58}
\contentsline {section}{\numberline {5.2}Entropic Coding}{92}{section.5.2}
\contentsline {paragraph}{Probabilistic modeling.}{93}{section*.59}
\contentsline {paragraph}{Huffman code.}{93}{section*.60}
\contentsline {section}{\numberline {5.3}JPEG-2000}{93}{section.5.3}
\contentsline {paragraph}{Dyadic quantization.}{94}{section*.61}
\contentsline {paragraph}{Steam packing.}{94}{section*.62}
\contentsline {paragraph}{Bit plane coding pass.}{94}{section*.63}
\contentsline {paragraph}{Contextual coder.}{94}{section*.64}
\contentsline {chapter}{\numberline {6}Denoising}{97}{chapter.6}
\contentsline {section}{\numberline {6.1}Noise Modeling}{97}{section.6.1}
\contentsline {subsection}{\numberline {6.1.1}Noise in Images}{97}{subsection.6.1.1}
\contentsline {subsection}{\numberline {6.1.2}Image Formation}{98}{subsection.6.1.2}
\contentsline {paragraph}{Additive Noise.}{98}{section*.65}
\contentsline {subsection}{\numberline {6.1.3}Denoiser}{99}{subsection.6.1.3}
\contentsline {section}{\numberline {6.2}Linear Denoising using Filtering}{99}{section.6.2}
\contentsline {subsection}{\numberline {6.2.1}Translation Invariant Estimators}{99}{subsection.6.2.1}
\contentsline {subsection}{\numberline {6.2.2}Optimal Filter Selection}{100}{subsection.6.2.2}
\contentsline {subsection}{\numberline {6.2.3}Wiener Filter}{100}{subsection.6.2.3}
\contentsline {subsection}{\numberline {6.2.4}Denoising and Linear Approximation}{101}{subsection.6.2.4}
\contentsline {section}{\numberline {6.3}Non-linear Denoising using Thresholding}{104}{section.6.3}
\contentsline {subsection}{\numberline {6.3.1}Hard Thresholding}{104}{subsection.6.3.1}
\contentsline {subsection}{\numberline {6.3.2}Soft Thresholding}{105}{subsection.6.3.2}
\contentsline {paragraph}{Coarse scale management.}{106}{section*.66}
\contentsline {paragraph}{Empirical choice of the threshold.}{106}{section*.67}
\contentsline {subsection}{\numberline {6.3.3}Minimax Optimality of Thresholding}{106}{subsection.6.3.3}
\contentsline {paragraph}{Sparse coefficients estimation.}{106}{section*.68}
\contentsline {paragraph}{Universal threshold value.}{107}{section*.69}
\contentsline {paragraph}{Asymptotic optimality.}{107}{section*.70}
\contentsline {subsection}{\numberline {6.3.4}Translation Invariant Thresholding Estimators}{108}{subsection.6.3.4}
\contentsline {paragraph}{Translation invariance.}{108}{section*.71}
\contentsline {paragraph}{Cycle spinning.}{109}{section*.72}
\contentsline {paragraph}{Translation invariant wavelet frame.}{109}{section*.73}
\contentsline {subsection}{\numberline {6.3.5}Exotic Thresholdings}{110}{subsection.6.3.5}
\contentsline {paragraph}{Semi-soft thresholding.}{111}{section*.74}
\contentsline {paragraph}{Stein thresholding.}{111}{section*.75}
\contentsline {subsection}{\numberline {6.3.6}Block Thresholding}{111}{subsection.6.3.6}
\contentsline {section}{\numberline {6.4}Data-dependant Noises}{113}{section.6.4}
\contentsline {subsection}{\numberline {6.4.1}Poisson Noise}{114}{subsection.6.4.1}
\contentsline {paragraph}{Poisson model.}{114}{section*.76}
\contentsline {paragraph}{Variance stabilization.}{115}{section*.77}
\contentsline {subsection}{\numberline {6.4.2}Multiplicative Noise}{117}{subsection.6.4.2}
\contentsline {paragraph}{Multiplicative image formation.}{117}{section*.78}
\contentsline {chapter}{\numberline {7}Variational Priors and Regularization}{121}{chapter.7}
\contentsline {section}{\numberline {7.1}Sobolev and Total Variation Priors}{121}{section.7.1}
\contentsline {subsection}{\numberline {7.1.1}Continuous Priors}{121}{subsection.7.1.1}
\contentsline {paragraph}{Sobolev prior.}{121}{section*.79}
\contentsline {paragraph}{Total variation prior.}{121}{section*.80}
\contentsline {subsection}{\numberline {7.1.2}Discrete Priors}{121}{subsection.7.1.2}
\contentsline {paragraph}{Discrete gradient.}{122}{section*.81}
\contentsline {paragraph}{Discrete divergence.}{122}{section*.82}
\contentsline {paragraph}{Discrete laplacian.}{123}{section*.83}
\contentsline {paragraph}{Discrete energies.}{124}{section*.84}
\contentsline {section}{\numberline {7.2}PDE and Energy Minimization}{124}{section.7.2}
\contentsline {subsection}{\numberline {7.2.1}General Flows}{124}{subsection.7.2.1}
\contentsline {subsection}{\numberline {7.2.2}Heat Flow}{124}{subsection.7.2.2}
\contentsline {paragraph}{Continuous in space.}{125}{section*.85}
\contentsline {paragraph}{Discrete in space.}{125}{section*.86}
\contentsline {subsection}{\numberline {7.2.3}Total Variation Flows}{125}{subsection.7.2.3}
\contentsline {paragraph}{Total variation gradient.}{125}{section*.87}
\contentsline {paragraph}{Regularized total variation.}{126}{section*.88}
\contentsline {paragraph}{Regularized total variation flow.}{127}{section*.89}
\contentsline {subsection}{\numberline {7.2.4}PDE Flows for Denoising}{127}{subsection.7.2.4}
\contentsline {section}{\numberline {7.3}Regularization for Denoising}{128}{section.7.3}
\contentsline {subsection}{\numberline {7.3.1}Regularization}{128}{subsection.7.3.1}
\contentsline {subsection}{\numberline {7.3.2}Sobolev Regularization}{129}{subsection.7.3.2}
\contentsline {subsection}{\numberline {7.3.3}TV Regularization}{130}{subsection.7.3.3}
\contentsline {chapter}{\numberline {8}Inverse Problems}{133}{chapter.8}
\contentsline {section}{\numberline {8.1}Inverse Problems Regularization}{133}{section.8.1}
\contentsline {paragraph}{Denoising.}{133}{section*.90}
\contentsline {paragraph}{De-blurring and super-resolution.}{133}{section*.91}
\contentsline {paragraph}{Interpolation and inpainting.}{134}{section*.92}
\contentsline {paragraph}{Medical imaging.}{134}{section*.93}
\contentsline {paragraph}{Regression for supervised learning.}{134}{section*.94}
\contentsline {section}{\numberline {8.2}Theoretical Study of Quadratic Regularization}{135}{section.8.2}
\contentsline {subsection}{\numberline {8.2.1}Singular Value Decomposition}{135}{subsection.8.2.1}
\contentsline {paragraph}{Finite dimension.}{135}{section*.95}
\contentsline {paragraph}{Compact operators.}{136}{section*.96}
\contentsline {paragraph}{Pseudo inverse.}{136}{section*.97}
\contentsline {subsection}{\numberline {8.2.2}Tikonov Regularization}{137}{subsection.8.2.2}
\contentsline {paragraph}{Regularized inverse.}{137}{section*.98}
\contentsline {paragraph}{Variational regularization.}{137}{section*.99}
\contentsline {paragraph}{Source condition.}{138}{section*.100}
\contentsline {paragraph}{Sublinear convergence speed.}{138}{section*.101}
\contentsline {section}{\numberline {8.3}Quadratic Regularization}{140}{section.8.3}
\contentsline {paragraph}{Convex regularization.}{140}{section*.102}
\contentsline {paragraph}{Quadratic Regularization.}{141}{section*.103}
\contentsline {paragraph}{Example of convolution.}{141}{section*.104}
\contentsline {subsection}{\numberline {8.3.1}Solving Linear System}{142}{subsection.8.3.1}
\contentsline {section}{\numberline {8.4}Non-Quadratic Regularization}{142}{section.8.4}
\contentsline {subsection}{\numberline {8.4.1}Total Variation Regularization}{142}{subsection.8.4.1}
\contentsline {paragraph}{Total variation.}{143}{section*.105}
\contentsline {paragraph}{Discretized Total variation.}{143}{section*.106}
\contentsline {subsection}{\numberline {8.4.2}Gradient Descent Method}{144}{subsection.8.4.2}
\contentsline {subsection}{\numberline {8.4.3}Examples of Gradient Computation}{144}{subsection.8.4.3}
\contentsline {section}{\numberline {8.5}Examples of Inverse Problems}{145}{section.8.5}
\contentsline {subsection}{\numberline {8.5.1}Deconvolution}{145}{subsection.8.5.1}
\contentsline {subsection}{\numberline {8.5.2}Inpainting}{145}{subsection.8.5.2}
\contentsline {subsection}{\numberline {8.5.3}Tomography Inversion}{146}{subsection.8.5.3}
\contentsline {chapter}{\numberline {9}Sparse Regularization}{151}{chapter.9}
\contentsline {section}{\numberline {9.1}Sparsity Priors}{151}{section.9.1}
\contentsline {subsection}{\numberline {9.1.1}Ideal sparsity prior.}{151}{subsection.9.1.1}
\contentsline {subsection}{\numberline {9.1.2}Convex relaxation}{151}{subsection.9.1.2}
\contentsline {subsection}{\numberline {9.1.3}Sparse Regularization and Thresholding}{152}{subsection.9.1.3}
\contentsline {section}{\numberline {9.2}Sparse Regularization of Inverse Problems}{154}{section.9.2}
\contentsline {paragraph}{Analysis vs. synthesis priors.}{154}{section*.107}
\contentsline {section}{\numberline {9.3}Iterative Soft Thresholding Algorithm}{154}{section.9.3}
\contentsline {subsection}{\numberline {9.3.1}Noiseless Recovery as a Linear Program}{155}{subsection.9.3.1}
\contentsline {subsection}{\numberline {9.3.2}Projected Gradient Descent for $\ell ^1$.}{155}{subsection.9.3.2}
\contentsline {subsection}{\numberline {9.3.3}Iterative Soft Thresholding and Forward Backward}{156}{subsection.9.3.3}
\contentsline {section}{\numberline {9.4}Example: Sparse Deconvolution}{157}{section.9.4}
\contentsline {subsection}{\numberline {9.4.1}Sparse Spikes Deconvolution}{157}{subsection.9.4.1}
\contentsline {subsection}{\numberline {9.4.2}Sparse Wavelets Deconvolution}{157}{subsection.9.4.2}
\contentsline {subsection}{\numberline {9.4.3}Sparse Inpainting}{158}{subsection.9.4.3}
\contentsline {chapter}{\numberline {10}Theory of Sparse Regularization}{163}{chapter.10}
\contentsline {section}{\numberline {10.1}Existence and Uniqueness}{163}{section.10.1}
\contentsline {subsection}{\numberline {10.1.1}Existence}{163}{subsection.10.1.1}
\contentsline {subsection}{\numberline {10.1.2}Polytope Projection for the Constraint Problem}{163}{subsection.10.1.2}
\contentsline {subsection}{\numberline {10.1.3}Optimality Conditions}{165}{subsection.10.1.3}
\contentsline {subsection}{\numberline {10.1.4}Uniqueness}{166}{subsection.10.1.4}
\contentsline {subsection}{\numberline {10.1.5}Duality}{167}{subsection.10.1.5}
\contentsline {section}{\numberline {10.2}Consistency and Sparsitency}{168}{section.10.2}
\contentsline {subsection}{\numberline {10.2.1}Bregman Divergence Rates for General Regularizations}{168}{subsection.10.2.1}
\contentsline {subsection}{\numberline {10.2.2}Linear Rates in Norms for $\ell ^1$ Regularization}{170}{subsection.10.2.2}
\contentsline {subsection}{\numberline {10.2.3}Sparsistency for Low Noise}{171}{subsection.10.2.3}
\contentsline {subsection}{\numberline {10.2.4}Sparsistency for Arbitrary Noise}{174}{subsection.10.2.4}
\contentsline {section}{\numberline {10.3}Sparse Deconvolution Case Study}{174}{section.10.3}
\contentsline {chapter}{\numberline {11}Compressed Sensing}{179}{chapter.11}
\contentsline {section}{\numberline {11.1}Motivation and Potential Applications}{179}{section.11.1}
\contentsline {subsection}{\numberline {11.1.1}Single Pixel Camera}{179}{subsection.11.1.1}
\contentsline {subsection}{\numberline {11.1.2}Sparse Recovery}{180}{subsection.11.1.2}
\contentsline {section}{\numberline {11.2}Dual Certificate Theory and Non-Uniform Guarantees}{181}{section.11.2}
\contentsline {subsection}{\numberline {11.2.1}Random Projection of Polytopes}{181}{subsection.11.2.1}
\contentsline {subsection}{\numberline {11.2.2}Random Matrices}{181}{subsection.11.2.2}
\contentsline {paragraph}{Linear growth $P = s/\beta $. }{181}{section*.108}
\contentsline {paragraph}{Super-linear grows $P = s \qopname \relax o{log}(\ldots )$. }{181}{section*.109}
\contentsline {subsection}{\numberline {11.2.3}Dual Certificates}{183}{subsection.11.2.3}
\contentsline {paragraph}{Coherence-based analysis.}{183}{section*.110}
\contentsline {paragraph}{Randomized analysis of the Fuchs certificate.}{184}{section*.111}
\contentsline {section}{\numberline {11.3}RIP Theory for Uniform Guarantees}{186}{section.11.3}
\contentsline {subsection}{\numberline {11.3.1}Restricted Isometry Constants}{186}{subsection.11.3.1}
\contentsline {subsection}{\numberline {11.3.2}RIP implies dual certificates}{187}{subsection.11.3.2}
\contentsline {subsection}{\numberline {11.3.3}RIP implies stable recovery}{189}{subsection.11.3.3}
\contentsline {subsection}{\numberline {11.3.4}Fourier sampling RIP}{190}{subsection.11.3.4}
\contentsline {chapter}{\numberline {12}Basics of Machine Learning}{193}{chapter.12}
\contentsline {section}{\numberline {12.1}Unsupervised Learning}{193}{section.12.1}
\contentsline {subsection}{\numberline {12.1.1}Dimensionality Reduction and PCA}{193}{subsection.12.1.1}
\contentsline {paragraph}{Presentation of the method.}{193}{section*.112}
\contentsline {paragraph}{Optimality analysis.}{194}{section*.113}
\contentsline {subsection}{\numberline {12.1.2}Clustering and $k$-means}{197}{subsection.12.1.2}
\contentsline {paragraph}{$k$-means}{197}{section*.114}
\contentsline {paragraph}{$k$-means++}{197}{section*.115}
\contentsline {paragraph}{Lloyd algorithm and continuous densities.}{198}{section*.116}
\contentsline {section}{\numberline {12.2}Empirical Risk Minimization}{198}{section.12.2}
\contentsline {subsection}{\numberline {12.2.1}Empirical Risk}{199}{subsection.12.2.1}
\contentsline {subsection}{\numberline {12.2.2}Prediction and Consistency}{199}{subsection.12.2.2}
\contentsline {subsection}{\numberline {12.2.3}Parametric Approaches and Regularization}{200}{subsection.12.2.3}
\contentsline {paragraph}{Prediction vs. estimation risks.}{200}{section*.117}
\contentsline {subsection}{\numberline {12.2.4}Testing Set and Cross-validation}{200}{subsection.12.2.4}
\contentsline {section}{\numberline {12.3}Supervised Learning: Regression}{200}{section.12.3}
\contentsline {subsection}{\numberline {12.3.1}Linear Regression}{201}{subsection.12.3.1}
\contentsline {paragraph}{Least square and conditional expectation.}{201}{section*.118}
\contentsline {paragraph}{Penalized linear models.}{202}{figure.12.10}
\contentsline {paragraph}{Ridge regression (quadratic penalization).}{203}{section*.120}
\contentsline {section}{\numberline {12.4}Supervised Learning: Classification}{203}{section.12.4}
\contentsline {subsection}{\numberline {12.4.1}Nearest Neighbors Classification}{203}{subsection.12.4.1}
\contentsline {subsection}{\numberline {12.4.2}Two Classes Logistic Classification}{204}{subsection.12.4.2}
\contentsline {paragraph}{Approximate risk minimization.}{204}{section*.121}
\contentsline {paragraph}{Logistic loss probabilistic interpretation.}{205}{section*.122}
\contentsline {paragraph}{Gradient descent method.}{206}{section*.123}
\contentsline {subsection}{\numberline {12.4.3}Multi-Classes Logistic Classification}{207}{subsection.12.4.3}
\contentsline {section}{\numberline {12.5}Kernel Methods}{208}{section.12.5}
\contentsline {subsection}{\numberline {12.5.1}Feature Map and Kernels}{209}{subsection.12.5.1}
\contentsline {subsection}{\numberline {12.5.2}Kernel Design}{210}{subsection.12.5.2}
\contentsline {paragraph}{Kernel on non-Euclidean spaces.}{211}{section*.124}
\contentsline {subsection}{\numberline {12.5.3}General Case}{211}{subsection.12.5.3}
\contentsline {section}{\numberline {12.6}Probably approximately correct learning theory}{212}{section.12.6}
\contentsline {subsection}{\numberline {12.6.1}Non parametric setup and calibration}{213}{subsection.12.6.1}
\contentsline {paragraph}{Risk decomposition}{213}{section*.125}
\contentsline {paragraph}{Calibration in the classification setup}{214}{section*.126}
\contentsline {subsection}{\numberline {12.6.2}PAC bounds}{214}{subsection.12.6.2}
\contentsline {paragraph}{Bias-variance decomposition.}{214}{section*.127}
\contentsline {paragraph}{Approximation error.}{214}{section*.128}
\contentsline {paragraph}{Estimation error.}{215}{section*.129}
\contentsline {chapter}{\numberline {13}Optimization \& Machine Learning: Smooth Optimization}{217}{chapter.13}
\contentsline {section}{\numberline {13.1}Motivation in Machine Learning}{217}{section.13.1}
\contentsline {subsection}{\numberline {13.1.1}Unconstraint optimization}{217}{subsection.13.1.1}
\contentsline {subsection}{\numberline {13.1.2}Regression}{218}{subsection.13.1.2}
\contentsline {subsection}{\numberline {13.1.3}Classification}{218}{subsection.13.1.3}
\contentsline {section}{\numberline {13.2}Basics of Convex Analysis}{218}{section.13.2}
\contentsline {subsection}{\numberline {13.2.1}Existence of Solutions}{218}{subsection.13.2.1}
\contentsline {subsection}{\numberline {13.2.2}Convexity}{219}{subsection.13.2.2}
\contentsline {paragraph}{Strict convexity.}{219}{section*.130}
\contentsline {subsection}{\numberline {13.2.3}Convex Sets}{220}{subsection.13.2.3}
\contentsline {section}{\numberline {13.3}Derivative and gradient}{220}{section.13.3}
\contentsline {subsection}{\numberline {13.3.1}Gradient}{220}{subsection.13.3.1}
\contentsline {subsection}{\numberline {13.3.2}First Order Conditions}{221}{subsection.13.3.2}
\contentsline {subsection}{\numberline {13.3.3}Least Squares}{222}{subsection.13.3.3}
\contentsline {subsection}{\numberline {13.3.4}Link with PCA}{223}{subsection.13.3.4}
\contentsline {subsection}{\numberline {13.3.5}Classification}{224}{subsection.13.3.5}
\contentsline {subsection}{\numberline {13.3.6}Chain Rule}{224}{subsection.13.3.6}
\contentsline {section}{\numberline {13.4}Gradient Descent Algorithm}{225}{section.13.4}
\contentsline {subsection}{\numberline {13.4.1}Steepest Descent Direction}{225}{subsection.13.4.1}
\contentsline {subsection}{\numberline {13.4.2}Gradient Descent}{226}{subsection.13.4.2}
\contentsline {section}{\numberline {13.5}Convergence Analysis}{227}{section.13.5}
\contentsline {subsection}{\numberline {13.5.1}Quadratic Case}{227}{subsection.13.5.1}
\contentsline {paragraph}{Convergence analysis for the quadratic case.}{227}{section*.131}
\contentsline {subsection}{\numberline {13.5.2}General Case}{230}{subsection.13.5.2}
\contentsline {paragraph}{Hessian.}{230}{section*.132}
\contentsline {paragraph}{Smoothness and strong convexity.}{231}{section*.133}
\contentsline {paragraph}{Convergence analysis.}{232}{section*.134}
\contentsline {subsection}{\numberline {13.5.3}Acceleration}{233}{subsection.13.5.3}
\contentsline {chapter}{\numberline {14}Optimization \& Machine Learning: Advanced Topics}{235}{chapter.14}
\contentsline {section}{\numberline {14.1}Regularization}{235}{section.14.1}
\contentsline {subsection}{\numberline {14.1.1}Penalized Least Squares}{235}{subsection.14.1.1}
\contentsline {subsection}{\numberline {14.1.2}Ridge Regression}{235}{subsection.14.1.2}
\contentsline {paragraph}{Pseudo-inverse.}{236}{section*.135}
\contentsline {subsection}{\numberline {14.1.3}Lasso}{237}{subsection.14.1.3}
\contentsline {subsection}{\numberline {14.1.4}Iterative Soft Thresholding}{237}{subsection.14.1.4}
\contentsline {section}{\numberline {14.2}Stochastic Optimization}{238}{section.14.2}
\contentsline {subsection}{\numberline {14.2.1}Minimizing Sums and Expectation}{239}{subsection.14.2.1}
\contentsline {subsection}{\numberline {14.2.2}Batch Gradient Descent (BGD)}{239}{subsection.14.2.2}
\contentsline {subsection}{\numberline {14.2.3}Stochastic Gradient Descent (SGD)}{240}{subsection.14.2.3}
\contentsline {subsection}{\numberline {14.2.4}Stochastic Gradient Descent with Averaging (SGA)}{242}{subsection.14.2.4}
\contentsline {subsection}{\numberline {14.2.5}Stochastic Averaged Gradient Descent (SAG)}{243}{subsection.14.2.5}
\contentsline {section}{\numberline {14.3}Automatic Differentiation}{243}{section.14.3}
\contentsline {subsection}{\numberline {14.3.1}Finite Differences and Symbolic Calculus}{244}{subsection.14.3.1}
\contentsline {subsection}{\numberline {14.3.2}Computational Graphs}{244}{subsection.14.3.2}
\contentsline {subsection}{\numberline {14.3.3}Forward Mode of Automatic Differentiation}{244}{subsection.14.3.3}
\contentsline {paragraph}{Simple example.}{245}{section*.136}
\contentsline {paragraph}{Dual numbers.}{246}{section*.137}
\contentsline {subsection}{\numberline {14.3.4}Reverse Mode of Automatic Differentiation}{247}{subsection.14.3.4}
\contentsline {paragraph}{Back-propagation.}{247}{section*.138}
\contentsline {paragraph}{Simple example.}{247}{section*.139}
\contentsline {subsection}{\numberline {14.3.5}Feed-forward Compositions}{248}{subsection.14.3.5}
\contentsline {subsection}{\numberline {14.3.6}Feed-forward Architecture}{248}{subsection.14.3.6}
\contentsline {paragraph}{Multilayers perceptron.}{249}{section*.140}
\contentsline {paragraph}{Link with adjoint state method.}{249}{section*.141}
\contentsline {subsection}{\numberline {14.3.7}Recurrent Architectures}{250}{subsection.14.3.7}
\contentsline {paragraph}{Residual recurrent networks. }{250}{section*.142}
\contentsline {paragraph}{Mitigating memory requirement. }{250}{section*.143}
\contentsline {paragraph}{Fixed point maps}{251}{section*.144}
\contentsline {paragraph}{Argmin layers}{251}{section*.145}
\contentsline {paragraph}{Sinkhorn's algorithm}{252}{section*.146}
\contentsline {chapter}{\numberline {15}Shallow Learning}{253}{chapter.15}
\contentsline {section}{\numberline {15.1}Recap on Supervised Learning}{253}{section.15.1}
\contentsline {section}{\numberline {15.2}Multi-layer Perceptron}{254}{section.15.2}
\contentsline {paragraph}{Expressiveness. }{254}{section*.147}
\contentsline {section}{\numberline {15.3}Training a MLP}{254}{section.15.3}
\contentsline {paragraph}{Optimizing with respect to $a$.}{254}{section*.148}
\contentsline {paragraph}{Optimizing with respect to $W$.}{255}{section*.149}
\contentsline {section}{\numberline {15.4}Controlling the Estimation Error}{255}{section.15.4}
\contentsline {section}{\numberline {15.5}Universality}{255}{section.15.5}
\contentsline {paragraph}{Proof in dimension $p=1$.}{256}{section*.150}
\contentsline {paragraph}{Proof in arbitrary dimension $d$.}{256}{section*.151}
\contentsline {section}{\numberline {15.6}Approximation Rates}{257}{section.15.6}
\contentsline {subsection}{\numberline {15.6.1}Barron's spaces}{257}{subsection.15.6.1}
\contentsline {subsection}{\numberline {15.6.2}Barron's Theorem}{258}{subsection.15.6.2}
\contentsline {paragraph}{Integral representation using a probability distribution}{258}{section*.152}
\contentsline {paragraph}{Discretization}{259}{section*.153}
\contentsline {subsection}{\numberline {15.6.3}Integral representation over $w$}{260}{subsection.15.6.3}
\contentsline {paragraph}{Integral representation using a signed measure.}{260}{section*.154}
\contentsline {paragraph}{Convex learning.}{260}{section*.155}
\contentsline {paragraph}{Revisiting Barron's proof using Frank-Wolfe}{260}{section*.156}
\contentsline {chapter}{\numberline {16}Deep Learning}{263}{chapter.16}
\contentsline {section}{\numberline {16.1}Deep Architectures}{263}{section.16.1}
\contentsline {subsection}{\numberline {16.1.1}Deep Network Structure}{263}{subsection.16.1.1}
\contentsline {paragraph}{Feedforward architectures.}{263}{section*.157}
\contentsline {paragraph}{Deep MLP.}{264}{section*.158}
\contentsline {subsection}{\numberline {16.1.2}Perceptron and Shallow Models}{264}{subsection.16.1.2}
\contentsline {subsection}{\numberline {16.1.3}Convolutional Neural Networks}{265}{subsection.16.1.3}
\contentsline {subsection}{\numberline {16.1.4}Advanced Architectures}{267}{subsection.16.1.4}
\contentsline {paragraph}{Residual Networks}{267}{section*.159}
\contentsline {paragraph}{Batch normalization}{267}{section*.160}
\contentsline {paragraph}{Transformers Networks}{267}{section*.161}
\contentsline {subsection}{\numberline {16.1.5}Scattering Transform}{267}{subsection.16.1.5}
\contentsline {chapter}{\numberline {17}Convex Analysis}{269}{chapter.17}
\contentsline {section}{\numberline {17.1}Basics of Convex Analysis}{269}{section.17.1}
\contentsline {subsection}{\numberline {17.1.1}Convex Sets and Functions}{269}{subsection.17.1.1}
\contentsline {subsection}{\numberline {17.1.2}First Order Conditions}{270}{subsection.17.1.2}
\contentsline {paragraph}{Existence of minimizers.}{270}{section*.162}
\contentsline {paragraph}{Sub-differential.}{270}{section*.163}
\contentsline {paragraph}{First Order Conditions.}{271}{section*.164}
\contentsline {paragraph}{Sub-differential calculus.}{271}{section*.165}
\contentsline {paragraph}{Normal cone.}{272}{section*.166}
\contentsline {section}{\numberline {17.2}Legendre-Fenchel Transform}{272}{section.17.2}
\contentsline {subsection}{\numberline {17.2.1}Legendre Transform}{273}{subsection.17.2.1}
\contentsline {subsection}{\numberline {17.2.2}Legendre transform and smoothness}{273}{subsection.17.2.2}
\contentsline {section}{\numberline {17.3}Convex Duality}{274}{section.17.3}
\contentsline {subsection}{\numberline {17.3.1}Lagrange Duality: Afine Constraint}{274}{subsection.17.3.1}
\contentsline {subsection}{\numberline {17.3.2}Lagrange Duality: General Case}{274}{subsection.17.3.2}
\contentsline {subsection}{\numberline {17.3.3}Fenchel-Rockafellar Duality}{276}{subsection.17.3.3}
\contentsline {chapter}{\numberline {18}Non-smooth Convex Optimization}{279}{chapter.18}
\contentsline {section}{\numberline {18.1}Descent Methods}{279}{section.18.1}
\contentsline {subsection}{\numberline {18.1.1}Gradient Descent}{279}{subsection.18.1.1}
\contentsline {subsection}{\numberline {18.1.2}Sub-gradient Descent}{279}{subsection.18.1.2}
\contentsline {subsection}{\numberline {18.1.3}Projected Gradient Descent}{280}{subsection.18.1.3}
\contentsline {section}{\numberline {18.2}Interior Point Methods}{280}{section.18.2}
\contentsline {section}{\numberline {18.3}Proximal Algorithm}{282}{section.18.3}
\contentsline {subsection}{\numberline {18.3.1}Proximal Map }{282}{subsection.18.3.1}
\contentsline {paragraph}{Examples}{282}{section*.167}
\contentsline {subsection}{\numberline {18.3.2}Basic Properties}{283}{subsection.18.3.2}
\contentsline {subsection}{\numberline {18.3.3}Related Concepts}{283}{subsection.18.3.3}
\contentsline {paragraph}{Link with sub-differential.}{283}{section*.168}
\contentsline {paragraph}{Link with duality.}{284}{section*.169}
\contentsline {paragraph}{Link with Moreau-Yosida regularization.}{284}{section*.170}
\contentsline {section}{\numberline {18.4}Proximal Gradient Algorithms}{284}{section.18.4}
\contentsline {subsection}{\numberline {18.4.1}Proximal Point Algorithm}{284}{subsection.18.4.1}
\contentsline {subsection}{\numberline {18.4.2}Forward-Backward}{285}{subsection.18.4.2}
\contentsline {paragraph}{Derivation using surrogate functionals.}{285}{section*.171}
\contentsline {paragraph}{Convergence of FB. }{286}{section*.172}
\contentsline {section}{\numberline {18.5}Primal-Dual Algorithms}{286}{section.18.5}
\contentsline {subsection}{\numberline {18.5.1}Forward-backward on the Dual}{286}{subsection.18.5.1}
\contentsline {subsection}{\numberline {18.5.2}Douglas-Rachford}{288}{subsection.18.5.2}
\contentsline {paragraph}{More than two functions.}{288}{section*.173}
\contentsline {paragraph}{Handling a linear operator.}{289}{section*.174}
\contentsline {subsection}{\numberline {18.5.3}Alternating Direction Method of Multipliers}{289}{subsection.18.5.3}
\contentsline {subsection}{\numberline {18.5.4}Primal-Dual Splitting}{291}{subsection.18.5.4}
