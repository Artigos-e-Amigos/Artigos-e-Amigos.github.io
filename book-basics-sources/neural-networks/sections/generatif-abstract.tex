Dans l'article précédent, nous avons vu comment entrainer de façon supervisée des réseaux de neurones. Ceci permet de résoudre efficacement des problèmes de classification, par exemple de reconnaissance d'images.  
%
Ce qui est peut être encore plus surprenant, c'est que ces réseaux de neurones sont également utilisés de façon non-supervisée afin de générer automatiquement des textes ou des images \guill{virtuelles}, ce que l'on appelle souvent des \guill{deep fakes}.
%
Dans ce second article, je tisserai un lien entre l'apprentissage de réseaux de neurones génératifs et la théorie du transport optimal. Ce problème a été posé par Gaspard Monge au 18$^e$ siècle, puis il a été reformulé par Leonid Kantorovitch au milieu du 20$^e$ siècle. Il est maintenant devenu un outil de choix pour aborder l'explosion récente de la science des données. 
%
% Le transport optimal est un problème très ancien, formulé par Monge au 18$^e$ siècle. Il a cependant fallu plusieurs révolutions mathématiques pour qu'il devienne un outil incontournable à la fois en théorie et en pratique, jusqu'à son utilisation récente en apprentissage machine.  
% 
% Cet article retrace ces révolutions, initiées par Leonid Kantorovitch pendant la seconde guerre mondiale. La formulation qu'il a proposée se prête à une analyse mathématique poussée ainsi qu'à son application à de nombreux problèmes. Elle fait du transport optimal un outil de choix pour aborder l'explosion récente de la science des données. 