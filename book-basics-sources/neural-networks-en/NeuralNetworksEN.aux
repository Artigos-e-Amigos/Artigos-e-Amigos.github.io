\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{hubel1962receptive}
\citation{hodgkin1952quantitative}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Discriminative Neural Networks}{3}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Algorithmics and mathematics of learning}{3}{section.1.1}}
\citation{mcculloch1943logical}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces  Example of a discriminative neural network with two layers. }}{4}{figure.1.1}}
\newlabel{fig:discriminative}{{1.1}{4}{Example of a discriminative neural network with two layers}{figure.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Discriminative neural networks}{4}{section.1.2}}
\citation{rosenblatt1957perceptron}
\citation{lecun2015deep}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces  Biological and artificial neurons. }}{5}{figure.1.2}}
\newlabel{fig:neuron}{{1.2}{5}{Biological and artificial neurons}{figure.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Supervised learning of a neural network}{5}{section.1.3}}
\citation{deng2009imagenet}
\citation{rumelhart1986learning}
\citation{linnainmaa1976taylor}
\citation{krizhevsky2012imagenet}
\citation{deng2009imagenet}
\citation{srivastava2014dropout}
\citation{cybenko1989approximation}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces  Examples of images from the ImageNet database\nobreakspace  {}\citep  {deng2009imagenet} used for learning. }}{6}{figure.1.3}}
\newlabel{fig:dataset}{{1.3}{6}{Examples of images from the ImageNet database~\cite {deng2009imagenet} used for learning}{figure.1.3}{}}
\citation{lecun1998gradient}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}The efficiency of neural networks}{7}{section.1.4}}
\citation{goodfellow2014generative}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Generative Neural Networks}{9}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Generative neural networks}{9}{section.2.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Unsupervised learning of generative networks}{9}{section.2.2}}
\newlabel{sec-app-gen}{{2.2}{9}{Unsupervised learning of generative networks}{section.2.2}{}}
\citation{Monge1781}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces  Example of a simplified generative neural network (a network for generating such complex images has more layers). }}{10}{figure.2.1}}
\newlabel{fig:generative}{{2.1}{10}{Example of a simplified generative neural network (a network for generating such complex images has more layers)}{figure.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces  Example on the left of a non-optimal permutation $s$ and on the right of the optimal permutation, in the case of $6$ points in dimension 2. }}{11}{figure.2.2}}
\newlabel{fig:otmonge}{{2.2}{11}{Example on the left of a non-optimal permutation $s$ and on the right of the optimal permutation, in the case of $6$ points in dimension 2}{figure.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Monge's optimal transport}{11}{section.2.3}}
\newlabel{sec-ot}{{2.3}{11}{Monge's optimal transport}{section.2.3}{}}
\citation{Monge1781}
\citation{Kantorovich42}
\citation{dantzig1990origins}
\citation{PeyreCuturi}
\citation{goodfellow2014generative}
\citation{martin2017wasserstein}
\citation{morgenstern1953theory}
\citation{nash1950equilibrium}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}The optimal transport of Kantorovitch}{12}{section.2.4}}
\newlabel{sec-kanto}{{2.4}{12}{The optimal transport of Kantorovitch}{section.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Adversarial networks}{12}{section.2.5}}
\citation{goodfellow2014generative}
\citation{brock2018large}
\bibstyle{plain}
\bibdata{biblio-nn}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces  Two examples of ``deep fakes'' which are virtual images interpolating between cats and dogs. }}{13}{figure.2.3}}
\newlabel{fig:deepfake}{{2.3}{13}{Two examples of \guill {deep fakes} which are virtual images interpolating between cats and dogs}{figure.2.3}{}}
\bibcite{martin2017wasserstein}{{1}{}{{}}{{}}}
\bibcite{brock2018large}{{2}{}{{}}{{}}}
\bibcite{cybenko1989approximation}{{3}{}{{}}{{}}}
\bibcite{dantzig1990origins}{{4}{}{{}}{{}}}
\bibcite{deng2009imagenet}{{5}{}{{}}{{}}}
\bibcite{goodfellow2014generative}{{6}{}{{}}{{}}}
\bibcite{hodgkin1952quantitative}{{7}{}{{}}{{}}}
\bibcite{hubel1962receptive}{{8}{}{{}}{{}}}
\bibcite{Kantorovich42}{{9}{}{{}}{{}}}
\bibcite{krizhevsky2012imagenet}{{10}{}{{}}{{}}}
\bibcite{lecun2015deep}{{11}{}{{}}{{}}}
\bibcite{lecun1998gradient}{{12}{}{{}}{{}}}
\bibcite{linnainmaa1976taylor}{{13}{}{{}}{{}}}
\bibcite{mcculloch1943logical}{{14}{}{{}}{{}}}
\bibcite{Monge1781}{{15}{}{{}}{{}}}
\bibcite{morgenstern1953theory}{{16}{}{{}}{{}}}
\bibcite{nash1950equilibrium}{{17}{}{{}}{{}}}
\bibcite{PeyreCuturi}{{18}{}{{}}{{}}}
\bibcite{rosenblatt1957perceptron}{{19}{}{{}}{{}}}
\bibcite{rumelhart1986learning}{{20}{}{{}}{{}}}
\bibcite{srivastava2014dropout}{{21}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
